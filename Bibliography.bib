@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}

@article{Stang:2016ca,
author = {Stang, Andreas and Deckert, Markus and Poole, Charles and Rothman, Kenneth J},
title = {{Statistical inference in abstracts of major medical and epidemiology journals 1975-2014: a systematic review.}},
journal = {European journal of epidemiology},
year = {2016},
month = nov
}


@article{SHERIDAN1995205,
title = "Teleoperation, telerobotics and telepresence: A progress report",
journal = "Control Engineering Practice",
volume = "3",
number = "2",
pages = "205 - 214",
year = "1995",
issn = "0967-0661",
doi = "https://doi.org/10.1016/0967-0661(94)00078-U",
url = "http://www.sciencedirect.com/science/article/pii/096706619400078U",
author = "T.B. Sheridan",
keywords = "man-machine systems, telerobotics, robotics, manipulation, human factors, computer interfaces, artificial intelligence",
abstract = "This paper briefly surveys and reports progress in the field of teleoperation, meaning human control of remote sensors and actuators. Included is the subclass of teleoperation called telerobotics, which means human supervisory control of remote semiautomatic systems, and the phenomenon of telepresence, in which special sensing and display technology enables the human to feel present at the remote location even though not really there. Current and new applications are reviewed. Techniques for human-computer cooperation in planning, commanding, and sensing are described. The telerobot is considered as a paradigm for any complex vehicle or process having many separate automatic control loops all of which are supervised by a human; some current examples are presented. Finally, opinions are given as to the current status of the field."
}

@article{Chen2007HumanPI,
  title={Human Performance Issues and User Interface Design for Teleoperated Robots},
  author={Jessie Y. C. Chen and E. C. Haas and Michael J. Barnes},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  year={2007},
  volume={37},
  pages={1231-1245}
}


@BOOK{NAP25118,
  author    = "National Academies of Sciences, Engineering, and Medicine",
  editor    = "Susan J. Debad",
  title     = "Learning from the Science of Cognition and Perception for Decision Making: Proceedings of a Workshop",
  isbn      = "978-0-309-47634-8",
  doi       = "10.17226/25118",
  abstract  = "Beginning in October 2017, the National Academies of Sciences, Engineering, and Medicine organized a set of workshops designed to gather information for the Decadal Survey of Social and Behavioral Sciences for Applications to National Security. The fourth workshop focused on the science of cognition and perception, and this publication summarizes the presentations and discussions from this workshop.",
  url       = "https://www.nap.edu/catalog/25118/learning-from-the-science-of-cognition-and-perception-for-decision-making",
  year      = 2018,
  publisher = "The National Academies Press",
  address   = "Washington, DC"
}

@article{SIMONS200516,
title = "Change blindness: past, present, and future",
journal = "Trends in Cognitive Sciences",
volume = "9",
number = "1",
pages = "16 - 20",
year = "2005",
issn = "1364-6613",
doi = "https://doi.org/10.1016/j.tics.2004.11.006",
url = "http://www.sciencedirect.com/science/article/pii/S1364661304002931",
author = "Daniel J. Simons and Ronald A. Rensink",
abstract = "Change blindness is the striking failure to see large changes that normally would be noticed easily. Over the past decade this phenomenon has greatly contributed to our understanding of attention, perception, and even consciousness. The surprising extent of change blindness explains its broad appeal, but its counterintuitive nature has also engendered confusions about the kinds of inferences that legitimately follow from it. Here we discuss the legitimate and the erroneous inferences that have been drawn, and offer a set of requirements to help separate them. In doing so, we clarify the genuine contributions of change blindness research to our understanding of visual perception and awareness, and provide a glimpse of some ways in which change blindness might shape future research."
}

@book{Bowman:2004:UIT:993837,
 author = {Bowman, Doug A. and Kruijff, Ernst and LaViola, Joseph J. and Poupyrev, Ivan},
 title = {3D User Interfaces: Theory and Practice},
 year = {2004},
 isbn = {0201758679},
 publisher = {Addison Wesley Longman Publishing Co., Inc.},
 address = {Redwood City, CA, USA},
} 

@article{fitts1954information,
  title={The information capacity of the human motor system in controlling the amplitude of movement.},
  author={Fitts, Paul M},
  journal={Journal of experimental psychology},
  volume={47},
  number={6},
  pages={381},
  year={1954},
  publisher={American Psychological Association}
}

%%
@article{chen2007human,
  title={Human performance issues and user interface design for teleoperated robots},
  author={Chen, Jessie YC and Haas, Ellen C and Barnes, Michael J},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={37},
  number={6},
  pages={1231--1245},
  year={2007},
  publisher={IEEE}
}

%%


%%
@ARTICLE{Mekuria, 
author={R. Mekuria and K. Blom and P. Cesar}, 
journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
title={Design, Implementation, and Evaluation of a Point Cloud Codec for Tele-Immersive Video}, 
year={2017}, 
volume={27}, 
number={4}, 
pages={828-842}, 
keywords={data compression;image colour analysis;image reconstruction;image representation;iterative methods;octrees;quantisation (signal);rate distortion theory;video coding;point cloud codec evaluation;point cloud codec implementation;point cloud codec design;teleimmersive video;real-time time-varying point cloud codec;3D immersive video;mixed reality applications;3D point cloud;intraframe coding;octree subdivision;interprediction algorithm;octree voxel space partition;rigid transform;iterative closest point algorithm;quaternion quantization scheme;color attribute;legacy image coding method;JPEG;generic compression framework;encoder;decoder;rate distortion performance;prediction distortion;3D virtual world;JTC1/SC29/WG11;augmented communication application;point-cloud compression solution;Three-dimensional displays;Codecs;Encoding;Octrees;Rendering (computer graphics);Streaming media;Real-time systems;Data compression;point clouds;teleconferencing;video codecs;virtual reality}, 
doi={10.1109/TCSVT.2016.2543039}, 
ISSN={1051-8215}, 
month={April},
comment = { .....}
}
%%

@article{Wickens2012,
author = {Wickens, Christopher D and Carswell, C Melody},
file = {:home/yonas/Downloads/519.pdf:pdf},
title = {{Chapter 5 Information Processing 2 Three Approaches To Information}},
year = {2012}
}
%%

%%
@article{PMID:11540969,
abstract = {Pilots were required to access information from a hierarchical aviation database by navigating under single-task conditions (Experiment 1) and when this task was time-shared with an altitude-monitoring task of varying bandwidth and priority (Experiment 2). In dual-task conditions, pilots had 2 viewports available, 1 always used for the information task and the other to be allocated to either task. Dual-task strategy, inferred from the decision of which task to allocate to the 2nd viewport, revealed that allocation was generally biased in favor of the monitoring task and was only partly sensitive to the difficulty of the 2 tasks and their relative priorities. Some dominant sources of navigational difficulties failed to adaptively influence selection strategy. The implications of the results are to provide tools for jumping to the top of the database, to provide 2 viewports into the common database, and to provide training as to the optimum viewport management strategy in a multitask environment.},
author = {Wickens, Christopher D. and Seidler, Karen S.},
doi = {10.1037/1076-898X.3.3.196},
isbn = {1076-898X},
issn = {1076898X},
journal = {Journal of Experimental Psychology: Applied},
number = {3},
pages = {196--215},
pmid = {11540969},
title = {{Information Access in a Dual-Task Context: Testing a Model of Optimal Strategy Selection}},
url = {https://doi.org/10.1037//1076-898X.3.3.196},
volume = {3},
year = {1997}
}
%%

%%
@article{pavlov1927conditional,
  title={Conditional reflexes: an investigation of the physiological activity of the cerebral cortex.},
  author={Pavlov, Ivan Petrovich},
  year={1927},
  publisher={Oxford Univ. Press}
}
%%

%%
@article{fitts1967human,
  title={Human performance.},
  author={Fitts, Paul M and Posner, Michael I},
  year={1967},
  publisher={Brooks/Cole}
}
%%

%%
@article{fitts1954information,
  title={The information capacity of the human motor system in controlling the amplitude of movement.},
  author={Fitts, Paul M},
  journal={Journal of experimental psychology},
  volume={47},
  number={6},
  pages={381},
  year={1954},
  publisher={American Psychological Association}
}
%%

%%
@article{Systems2001,
author = {Systems, Neural},
file = {:home/yonas/Downloads/Curr-Opinion-reprint.pdf:pdf},
pages = {505--509},
title = {{Sensory modalities are not separate}},
year = {2001}
}
%%

%%
@article{doi:10.1162/105474698565767,
author = {Stanney, Kay M. and Mourant, Ronald R. and Kennedy, Robert S.},
title = {Human Factors Issues in Virtual Environments: A Review of the Literature},
journal = {Presence: Teleoperators and Virtual Environments},
volume = {7},
number = {4},
pages = {327-351},
year = {1998},
doi = {10.1162/105474698565767},

URL = { 
        https://doi.org/10.1162/105474698565767
    
},
eprint = { 
        https://doi.org/10.1162/105474698565767
    
}
,
    abstract = { Virtual environments are envisioned as being systems that will enhance the communication between humans and computers. If virtual systems are to be effective and well received by their users, considerable human-factors research needs to be accomplished. This paper provides an overview of many of these human-factors issues, including human performance efficiency in virtual worlds (which is likely influenced by task characteristics, user characteristics, human sensory and motor physiology, multimodal interaction, and the potential need for new design metaphors); health and safety issues (of which cybersickness and deleterious physiological aftereffects may pose the most concern); and the social impact of the technology. The challenges each of these factors present to the effective design of virtual environments and systematic approaches to the resolution of each of these issues are discussed. }
}

%%

@article{Chen2014,
author = {Chen, Jessie and V. N. Oden, Razia and O Merritt, John},
year = {2014},
month = {01},
pages = {12-22},
title = {Utility of stereoscopic displays for indirect-vision driving and robot teleoperation},
volume = {57},
journal = {Ergonomics},
doi = {10.1080/00140139.2013.859739}
}
%%
@inproceedings{smyth2000indirect,
  title={Indirect vision driving with fixed flat panel displays for near unity, wide, and extended fields of camera view},
  author={Smyth, Christopher C},
  booktitle={Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  volume={44},
  number={36},
  pages={541--544},
  year={2000},
  organization={SAGE Publications Sage CA: Los Angeles, CA}}

@article{van2003image,
  title={Image parameters for driving with indirect viewing systems},
  author={Van Erp, Jan BF and Padmos, Pieter},
  journal={Ergonomics},
  volume={46},
  number={15},
  pages={1471--1499},
  year={2003},
  publisher={Taylor \& Francis}}
  
@inproceedings{wang2004gravity,
  title={Gravity-referenced attitude display for teleoperation of mobile robots},
  author={Wang, Jijun and Lewis, Michael and Hughes, Stephen},
  booktitle={Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  volume={48},
  number={23},
  pages={2662--2666},
  year={2004},
  organization={SAGE Publications Sage CA: Los Angeles, CA}
}
%%
@inproceedings{drury2006changing,
  title={Changing shape: Improving situation awareness for a polymorphic robot},
  author={Drury, Jill L and Yanco, Holly A and Howell, Whitney and Minten, Brian and Casper, Jennifer},
  booktitle={Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction},
  pages={72--79},
  year={2006},
  organization={ACM}
}
%%

@inproceedings{keyes2006camera,
  title={Camera placement and multi-camera fusion for remote robot operation},
  author={Keyes, Brenden and Casey, Robert and Yanco, Holly A and Maxwell, Bruce A and Georgiev, Yavor},
  booktitle={Proceedings of the IEEE international workshop on safety, security and rescue robotics},
  pages={22--24},
  year={2006},
  organization={National Institute of Standards and Technology Gaithersburg, MD}
}
%%
@article{olmos2000tactical,
  title={Tactical displays for combat awareness: An examination of dimensionality and frame of reference concepts and the application of cognitive engineering},
  author={Olmos, Oscar and Wickens, Christopher D and Chudy, Andrew},
  journal={The International Journal of Aviation Psychology},
  volume={10},
  number={3},
  pages={247--271},
  year={2000},
  publisher={Taylor \& Francis}
}
%%

@inproceedings{macias2019measuring,
  title={Measuring Performance in Robotic Teleoperation Tasks with Virtual Reality Headgear},
  author={Macia{\'s}, Mateusz and D{\k{a}}browski, Adam and Fra{\'s}, Jan and Karczewski, Micha{\l} and Puchalski, S{\l}awomir and Tabaka, Sebastian and Jaroszek, Piotr},
  booktitle={Conference on Automation},
  pages={408--417},
  year={2019},
  organization={Springer}
}
%%

@article{balasubramanian2012robust,
  title={A robust and sensitive metric for quantifying movement smoothness},
  author={Balasubramanian, Sivakumar and Melendez-Calderon, Alejandro and Burdet, Etienne},
  journal={IEEE transactions on biomedical engineering},
  volume={59},
  number={8},
  pages={2126--2136},
  year={2012},
  publisher={IEEE}
}
%%
@article{woods2004envisioning,
  title={Envisioning human-robot coordination in future operations},
  author={Woods, David D and Tittle, James and Feil, Magnus and Roesler, Axel},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={34},
  number={2},
  pages={210--218},
  year={2004},
  publisher={IEEE}
}

@Article{Suzuki2014,
author="Suzuki, Sho'ji
and Suda, Ryoutarou",
title="A vision system with wide field of view and collision alarms for teleoperation of mobile robots",
journal="ROBOMECH Journal",
year="2014",
month="Sep",
day="05",
volume="1",
number="1",
pages="8",
abstract="Vision systems are an important component to teleoperate mobile robots. We previously proposed a vision system with a wide field of view by combining the camera images of two cameras. This paper describes the features of our vision system that are useful for teleoperation, and we propose attachment devices for our system. The proposed devices are used to visualize the risk of collisions to the operator of robots. We performed two experiments to evaluate our vision system and the proposed devices.",
issn="2197-4225",
doi="10.1186/s40648-014-0008-5",
url="https://doi.org/10.1186/s40648-014-0008-5"
}

@article{drascic1993investigation,
  title={An investigation of monoscopic and stereoscopic video for teleoperation.},
  author={Drascic, David},
  year={1993}
}

@article{madl2011timing,
  title={The timing of the cognitive cycle},
  author={Madl, Tamas and Baars, Bernard J and Franklin, Stan},
  journal={PloS one},
  volume={6},
  number={4},
  pages={e14803},
  year={2011},
  publisher={Public Library of Science}
}

@article{kamsickas2003future,
  title={Future combat systems (FCS) concept and technology development (CTD) phase—Unmanned combat demonstration—Final report},
  author={Kamsickas, G},
  journal={Boeing Company, Seattle, WA, Tech. Rep. D786--1006102},
  year={2003}
}
@techreport{schipani1998quantification,
  title={Quantification of cognitive process degradation while mobile, attributable to the environmental stressors endurance, vibration, and noise},
  author={Schipani, Salvatore P and Bruno, Richard S and Lattin, Michael A and King, Bobby M and Patton, Debra J},
  year={1998},
  institution={ARMY RESEARCH LAB ABERDEEN PROVING GROUND MD}
}
@article{kebria2019robust,
  title={Robust Adaptive Control Scheme for Teleoperation Systems With Delay and Uncertainties},
  author={Kebria, Parham M and Khosravi, Abbas and Nahavandi, Saeid and Shi, Peng and Alizadehsani, Roohallah},
  journal={IEEE transactions on cybernetics},
  year={2019},
  publisher={IEEE}
}

%%

@article{passenberg2010survey,
  title={A survey of environment-, operator-, and task-adapted controllers for teleoperation systems},
  author={Passenberg, Carolina and Peer, Angelika and Buss, Martin},
  journal={Mechatronics},
  volume={20},
  number={7},
  pages={787--801},
  year={2010},
  publisher={Elsevier}
}

%%
@inproceedings{brooks1990telerobotic,
  title={Telerobotic response requirements},
  author={Brooks, Thurston L},
  booktitle={1990 IEEE International Conference on Systems, Man, and Cybernetics Conference Proceedings},
  pages={113--120},
  year={1990},
  organization={IEEE}
}

@article{Penin2018,
author = {Penin, Luis F},
file = {:C$\backslash$:/Users/ytefera/Downloads/Roman98.pdf:pdf},
number = {September 1998},
title = {{Human Operator Model for the Analysis of Teleoperated Systems with Bilateral Control Human Operator Model for the Analysis of Teleoperated Systems with Bilateral Control}},
year = {2018}
}

%%
@incollection{hess2018human,
  title={Human-in-the-loop control},
  author={Hess, RA},
  booktitle={Control System Applications},
  pages={327--334},
  year={2018},
  publisher={CRC Press}
}
%%

@article{mcruer1980human,
  title={Human dynamics in man-machine systems},
  author={McRuer, Duane},
  journal={Automatica},
  volume={16},
  number={3},
  pages={237--253},
  year={1980},
  publisher={Elsevier}
}

%%

@INPROCEEDINGS{6224647, 
author={J. {Kammerl} and N. {Blodow} and R. B. {Rusu} and S. {Gedikli} and M. {Beetz} and E. {Steinbach}}, 
booktitle={2012 IEEE International Conference on Robotics and Automation}, 
title={Real-time compression of point cloud streams}, 
year={2012}, 
volume={}, 
number={}, 
pages={778-785}, 
keywords={cloud computing;data compression;tree data structures;real-time compression;point cloud streams;novel lossy compression approach;coding complexity;coding precision;spatial decomposition;octree data structures;temporal redundancy;Octrees;Encoding;Decoding;Entropy;Real time systems;Sensors}, 
doi={10.1109/ICRA.2012.6224647}, 
ISSN={1050-4729}, 
month={May},}


@inproceedings{Keller:2013:RRD:2544744.2544784,
 author = {Keller, Maik and Lefloch, Damien and Lambers, Martin and Izadi, Shahram and Weyrich, Tim and Kolb, Andreas},
 title = {Real-Time 3D Reconstruction in Dynamic Scenes Using Point-Based Fusion},
 booktitle = {Proceedings of the 2013 International Conference on 3D Vision},
 series = {3DV '13},
 year = {2013},
 isbn = {978-0-7695-5067-1},
 pages = {1--8},
 numpages = {8},
 url = {http://dx.doi.org/10.1109/3DV.2013.9},
 doi = {10.1109/3DV.2013.9},
 acmid = {2544784},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {3D cameras and sensors, 3D shape reconstruction, Kinect Fusion, GPU, Real-time},
} 

@inproceedings{inproceedings,
author = {Rünz, Martin and Buffier, Maud and Agapito, Lourdes},
year = {2018},
month = {10},
pages = {10-20},
title = {MaskFusion: Real-Time Recognition, Tracking and Reconstruction of Multiple Moving Objects},
doi = {10.1109/ISMAR.2018.00024}
}
@article{Sitzmann2018,
abstract = {IEEE Understanding how people explore immersive virtual environments is crucial for many applications, such as designing virtual reality (VR) content, developing new compression algorithms, or learning computational models of saliency or visual attention. Whereas a body of recent work has focused on modeling saliency in desktop viewing conditions, VR is very different from these conditions in that viewing behavior is governed by stereoscopic vision and by the complex interaction of head orientation, gaze, and other kinematic constraints. To further our understanding of viewing behavior and saliency in VR, we capture and analyze gaze and head orientation data of 169 users exploring stereoscopic, static omni-directional panoramas, for a total of 1980 head and gaze trajectories for three different viewing conditions. We provide a thorough analysis of our data, which leads to several important insights, such as the existence of a particular fixation bias, which we then use to adapt existing saliency predictors to immersive VR conditions. In addition, we explore other applications of our data and analysis, including automatic alignment of VR video cuts, panorama thumbnails, panorama video synopsis, and saliency-based compression.},
author = {Sitzmann, Vincent and Serrano, Ana and Pavel, Amy and Agrawala, Maneesh and Gutierrez, Diego and Masia, Belen and Wetzstein, Gordon},
doi = {10.1109/TVCG.2018.2793599},
file = {:C$\backslash$:/Users/ytefera/Documents/Litrature/08269807.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Saliency,omnidirectional stereoscopic panoramas},
number = {4},
pages = {1633--1642},
publisher = {IEEE},
title = {{Saliency in VR: How Do People Explore Virtual Environments?}},
volume = {24},
year = {2018}
}

@article{Zollhofer2018,
abstract = {Figure 1: This state-of-the-art report provides an overview of RGB-D scene reconstruction approaches. We discuss recent trends in the geometric reconstruction of static (left) and dynamic scenes (middle) as well as the acquisition of corresponding color and reflectance (right). Abstract The advent of affordable consumer grade RGB-D cameras has brought about a profound advancement of visual scene recon-struction methods. Both computer graphics and computer vision researchers spend significant effort to develop entirely new algorithms to capture comprehensive shape models of static and dynamic scenes with RGB-D cameras. This led to significant advances of the state of the art along several dimensions. Some methods achieve very high reconstruction detail, despite limited sensor resolution. Others even achieve real-time performance, yet possibly at lower quality. New concepts were developed to capture scenes at larger spatial and temporal extent. Other recent algorithms flank shape reconstruction with concurrent material and lighting estimation, even in general scenes and unconstrained conditions. In this state-of-the-art report, we analyze these recent developments in RGB-D scene reconstruction in detail and review essential related work. We explain, compare, and critically analyze the common underlying algorithmic concepts that enabled these recent advancements. Furthermore, we show how algorithms are designed to best exploit the benefits of RGB-D data while suppressing their often non-trivial data distortions. In addition, this report identifies and discusses important open research questions and suggests relevant directions for future work.},
annote = {-best tracking
-surafce reconstruction
-},
author = {Zollh{\"{o}}fer, Michael and Stotko, Patrick and G{\"{o}}rlitz, Andreas and Theobalt, Christian and Nie{\ss}ner, Matthias and Klein, Reinhard and Kolb, Andreas},
doi = {10.1111/cgf.13386},
file = {:C$\backslash$:/Users/ytefera/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zollh{\"{o}}fer et al. - 2018 - State of the art on 3D reconstruction with RGB-D cameras.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {Appearance and texture representations,Computing methodologies,Motion capture,Reconstruction},
number = {2},
pages = {625--652},
title = {{State of the art on 3D reconstruction with RGB-D cameras}},
volume = {37},
year = {2018}
}

%%

@inproceedings{newcombe2015dynamicfusion,
  title={Dynamicfusion: Reconstruction and tracking of non-rigid scenes in real-time},
  author={Newcombe, Richard A and Fox, Dieter and Seitz, Steven M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={343--352},
  year={2015}
}

%%

@inproceedings{jaimez2017fast,
  title={Fast odometry and scene flow from RGB-D cameras based on geometric clustering},
  author={Jaimez, Mariano and Kerl, Christian and Gonzalez-Jimenez, Javier and Cremers, Daniel},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={3992--3999},
  year={2017},
  organization={IEEE}
}
%%

@inproceedings{scona2018staticfusion,
  title={StaticFusion: Background reconstruction for dense RGB-D SLAM in dynamic environments},
  author={Scona, Raluca and Jaimez, Mariano and Petillot, Yvan R and Fallon, Maurice and Cremers, Daniel},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

%%
@inproceedings{barnes2018driven,
  title={Driven to distraction: Self-supervised distractor learning for robust monocular visual odometry in urban environments},
  author={Barnes, Dan and Maddern, Will and Pascoe, Geoffrey and Posner, Ingmar},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1894--1900},
  year={2018},
  organization={IEEE}
}
%%
@article{bescos2018dynaslam,
  title={DynaSLAM: Tracking, mapping, and inpainting in dynamic scenes},
  author={Bescos, Berta and F{\'a}cil, Jos{\'e} M and Civera, Javier and Neira, Jos{\'e}},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={4},
  pages={4076--4083},
  year={2018},
  publisher={IEEE}
}
%%

@inproceedings{runz2017co,
  title={Co-fusion: Real-time segmentation, tracking and fusion of multiple objects},
  author={R{\"u}nz, Martin and Agapito, Lourdes},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4471--4478},
  year={2017},
  organization={IEEE}
}

%%

@inproceedings{barsan2018robust,
  title={Robust dense mapping for large-scale dynamic environments},
  author={B{\^a}rsan, Ioan Andrei and Liu, Peidong and Pollefeys, Marc and Geiger, Andreas},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7510--7517},
  year={2018},
  organization={IEEE}
}

%%

@inproceedings{runz2018maskfusion,
  title={Maskfusion: Real-time recognition, tracking and reconstruction of multiple moving objects},
  author={Runz, Martin and Buffier, Maud and Agapito, Lourdes},
  booktitle={2018 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  pages={10--20},
  year={2018},
  organization={IEEE}
}

%%

@inproceedings{xu2019mid,
  title={Mid-fusion: Octree-based object-level multi-instance dynamic SLAM},
  author={Xu, Binbin and Li, Wenbin and Tzoumanikas, Dimos and Bloesch, Michael and Davison, Andrew and Leutenegger, Stefan},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={5231--5237},
  year={2019},
  organization={IEEE}
}
%%

@article{narita2019panopticfusion,
  title={PanopticFusion: Online Volumetric Semantic Mapping at the Level of Stuff and Things},
  author={Narita, Gaku and Seno, Takashi and Ishikawa, Tomoya and Kaji, Yohsuke},
  journal={arXiv preprint arXiv:1903.01177},
  year={2019}
}

%%
@article{miksik2019live,
  title={Live Reconstruction of Large-Scale Dynamic Outdoor Worlds},
  author={Miksik, Ondrej and Vineet, Vibhav},
  journal={arXiv preprint arXiv:1903.06708},
  year={2019}
}
%%

@article{strecke2019fusion,
  title={EM-Fusion: Dynamic Object-Level SLAM with Probabilistic Data Association},
  author={Strecke, Michael and St{\"u}ckler, J{\"o}rg},
  journal={arXiv preprint arXiv:1904.11781},
  year={2019}
}
%%
@article{hachiuma2019detectfusion,
  title={DetectFusion: Detecting and Segmenting Both Known and Unknown Dynamic Objects in Real-time SLAM},
  author={Hachiuma, Ryo and Pirchheim, Christian and Schmalstieg, Dieter and Saito, Hideo},
  journal={arXiv preprint arXiv:1907.09127},
  year={2019}
}
%%
